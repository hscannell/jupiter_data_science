{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nonprofit-dating",
   "metadata": {},
   "source": [
    "### This notebook is the first step towards analyzing marine heatwaves using global sea surface temperature data\n",
    "\n",
    "The data is cloud optimized and analysis ready thanks to Pangeo-forge using OSN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fatty-medline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import s3fs\n",
    "import sys\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-bones",
   "metadata": {},
   "source": [
    "#### Import data\n",
    "- load the daily NOAA OISST dataset and resample to monthly means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "racial-appendix",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = 'https://ncsa.osn.xsede.org'\n",
    "fs_osn = s3fs.S3FileSystem(anon=True, client_kwargs={'endpoint_url': endpoint_url},) \n",
    "\n",
    "path = \"Pangeo/pangeo-forge/noaa_oisst/v2.1-avhrr.zarr\"\n",
    "ds = xr.open_zarr(fs_osn.get_mapper(path), consolidated=True).resample(time='MS').mean()\n",
    "sst = ds.sst.isel(zlev=0).drop('zlev')\n",
    "sst.load();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sudden-container",
   "metadata": {},
   "source": [
    "#### Decompose SST maps into mean, trend, annual, and semi-annual harmonics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-maine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform time into decimal year \n",
    "dyr = sst.time.dt.year + (sst.time.dt.month-0.5)/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subtle-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick check: global mean SST\n",
    "sst.mean(('lat','lon')).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-isaac",
   "metadata": {},
   "source": [
    "Use least-squares regression and solve for model coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-elephant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our 6 coefficient model is composed of the mean, trend, annual sine and cosine harmonics, & semi-annual sine and cosine harmonics\n",
    "model = np.array([np.ones(len(dyr))] + [dyr-np.mean(dyr)] + [np.sin(2*np.pi*dyr)] + [np.cos(2*np.pi*dyr)] + [np.sin(4*np.pi*dyr)] + [np.cos(4*np.pi*dyr)])\n",
    "\n",
    "# Take the pseudo-inverse of model to 'solve' least-squares problem\n",
    "pmodel = np.linalg.pinv(model)\n",
    "\n",
    "# Convert model and pmodel to xaray DataArray\n",
    "model_da = xr.DataArray(model.T, dims=['time','coeff'], coords={'time':sst.time.values, 'coeff':np.arange(1,7,1)}) \n",
    "pmodel_da = xr.DataArray(pmodel.T, dims=['coeff','time'], coords={'coeff':np.arange(1,7,1), 'time':sst.time.values})  \n",
    "\n",
    "# resulting coefficients of the model\n",
    "sst_mod = xr.DataArray(pmodel_da.dot(sst), dims=['coeff','lat','lon'], coords={'coeff':np.arange(1,7,1), 'lat':sst.lat.values, 'lon':sst.lon.values})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reported-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct mean, trend, and seasonal cycle\n",
    "mean = model_da[:,0].dot(sst_mod[0,:,:])\n",
    "trend = model_da[:,1].dot(sst_mod[1,:,:])\n",
    "seas = model_da[:,2:].dot(sst_mod[2:,:,:])\n",
    "\n",
    "# compute anomalies by removing all  the model coefficients \n",
    "ssta_notrend = sst-model_da.dot(sst_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-offer",
   "metadata": {},
   "source": [
    "#### Calculate summary statistics for marine heatwaves. \n",
    "\n",
    "Our criteria for marine heatwaves are consecutive months where the detrended and deseasonalized SST anomalies exceeds the local 90th percentile.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average statistics, global maps\n",
    "t90_global = ssta_notrend.quantile(.9)\n",
    "mhws = ssta_notrend.where(ssta_notrend>t90_global, drop=False, other=np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-oriental",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average event duration (months)\n",
    "avg_duration = np.empty(mhws[0,:,:].shape); avg_duration[:]= np.nan\n",
    "\n",
    "# Average event intensity (ÂºC)\n",
    "avg_intensity = np.empty(mhws[0,:,:].shape); avg_intensity[:]= np.nan\n",
    "\n",
    "# Number of total marine heatwave events\n",
    "avg_count = np.empty(mhws[0,:,:].shape); avg_count[:]= np.nan\n",
    "\n",
    "for i in range(0, mhws.shape[1]):\n",
    "    for j in range(0, mhws.shape[2]):\n",
    "        P = mhws[:,i,j].copy()\n",
    "        P.loc[~P.isnull()] = 1  # values that are not nan will be assigned as 1.\n",
    "        if np.nansum(P)==0:\n",
    "            continue\n",
    "        else:\n",
    "            duration = P.groupby(((P.shift()!=P).cumsum())-P).count()\n",
    "            # date = mhws[:,i,j].time.groupby(((P.shift() != P).cumsum())-P).mean()\n",
    "            avg_duration[i,j] = float(duration.mean().values)\n",
    "            avg_count[i,j] = duration.shape[0]\n",
    "            \n",
    "            intensity = mhws[:,i,j].groupby(((P.shift()!=P).cumsum())-P).mean()\n",
    "            avg_intensity[i,j] = float(intensity.mean().values)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-recycling",
   "metadata": {},
   "source": [
    "#### Save created variables to zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-missouri",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xarray Dataset to save\n",
    "ds_out = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        mean=(['time', 'lat', 'lon'], mean.values),\n",
    "        trend=(['time', 'lat', 'lon'], trend.values),\n",
    "        seas=(['time', 'lat', 'lon'], seas.values),\n",
    "        ssta_notrend=(['time', 'lat', 'lon'], ssta_notrend.values),\n",
    "        avg_duration=(['lat', 'lon'], avg_duration.values),\n",
    "        avg_count=(['lat', 'lon'], avg_count.values),\n",
    "        avg_intensity=(['lat', 'lon'], avg_intensity.values), \n",
    "        \n",
    "    ),\n",
    "    coords=dict(\n",
    "        lon=ds.lon,\n",
    "        lat=ds.lat,\n",
    "        time=ds.time,\n",
    "    ),\n",
    "    attrs=dict(description=\"OISST v2.1 preprocessed for Ocetrac\",\n",
    "              threshold='90th percentile',\n",
    "              climatology='entire period'),\n",
    ")\n",
    "ds_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-portable",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_out.to_netcdf('../preprocessed_oisst_mhw_stats.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marine-heatwaves",
   "language": "python",
   "name": "marine-heatwaves"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
